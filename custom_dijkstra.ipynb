{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Dijkstra\n",
    "- find all combinations between two points given minimum number of stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies  \n",
    "from collections import deque\n",
    "from heapq import heappop, heappush\n",
    "from itertools import count\n",
    "\n",
    "import networkx as nx\n",
    "from networkx.algorithms.shortest_paths.generic import _build_paths_from_predecessors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _weight_function(G, weight):\n",
    "    if callable(weight):\n",
    "        return weight\n",
    "    # If the weight keyword argument is not callable, we assume it is a\n",
    "    # string representing the edge attribute containing the weight of\n",
    "    # the edge.\n",
    "    if G.is_multigraph():\n",
    "        return lambda u, v, d: min(attr.get(weight, 1) for attr in d.values())\n",
    "    return lambda u, v, data: data.get(weight, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_source_dijkstra(G, sources, target=None, cutoff=None, weight=\"weight\"):\n",
    "    sources = {sources}\n",
    "    if not sources:\n",
    "        raise ValueError(\"sources must not be empty\")\n",
    "    for s in sources:\n",
    "        if s not in G:\n",
    "            raise nx.NodeNotFound(f\"Node {s} not found in graph\")\n",
    "    if target in sources:\n",
    "        return (0, [target])\n",
    "    weight = _weight_function(G, weight)\n",
    "    \n",
    "    paths = {source: [source] for source in sources}  # dictionary of paths\n",
    " \n",
    "    total_distance = _dijkstra_multisource(\n",
    "        G, sources, weight, paths=paths, cutoff=cutoff, target=target\n",
    "    )\n",
    "   \n",
    "    if target is None:\n",
    "        return (total_distance, paths)\n",
    "    try:\n",
    "        return (total_distance[target], paths[target])\n",
    "    except KeyError as err:\n",
    "        raise nx.NetworkXNoPath(f\"No path to {target}.\") from err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dijkstra(G, source, weight, pred=None, paths=None, cutoff=None, target=None):\n",
    "    return _dijkstra_multisource(\n",
    "        G, [source], weight, pred=pred, paths=paths, cutoff=cutoff, target=target\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nNOTES:  \\nTakes source and stores it in visited and adds to queue (initialization)\\nWhile loop\\n  pop queue\\n  take source (v); make sure node not traversed\\n  get destinations (u) via loop\\n  add destination 'cost/weight' to temporary distance variable\\n  update destination node (u) distance \\n  update visited with u\\n  add to queue the next node\\n  update destination list\\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "NOTES:  \n",
    "Takes source and stores it in visited and adds to queue (initialization)\n",
    "While loop\n",
    "  pop queue\n",
    "  take source (v); make sure node not traversed\n",
    "  get destinations (u) via loop\n",
    "  add destination 'cost/weight' to temporary distance variable\n",
    "  update destination node (u) distance \n",
    "  update visited with u\n",
    "  add to queue the next node\n",
    "  update destination list\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customized dijkstra from:  \n",
    "## starting code:  https://networkx.org/documentation/stable/_modules/networkx/algorithms/shortest_paths/weighted.html#multi_source_dijkstra \n",
    "\n",
    "def _dijkstra_multisource(\n",
    "    G, sources, weight, pred=None, paths=None, cutoff=None, target=None\n",
    "):\n",
    "    # G: graph of nodes\n",
    "    # sources: list of starting node(s)\n",
    "    # weight: weight function - minimized value\n",
    "    # pred: predecessors - dict of lists\n",
    "    # paths: dict holds list of nodes making path\n",
    "    # cutoff: maximum weight before search ends\n",
    "    # target: ending node\n",
    "    \n",
    "    G_succ = G._adj  # For speed-up (and works for both directed and undirected graphs)\n",
    "    push = heappush\n",
    "    pop = heappop\n",
    "    c = count()  # iterator\n",
    "    \n",
    "    # tracking progress\n",
    "    total_distance = {}  # dictionary of final distance\n",
    "    visited = {}  # nodes that have been visited\n",
    "    queue = []  # queue is heapq with 3-tuples (distance,c,node)\n",
    "    \n",
    "    # intilize heap with source(s)\n",
    "    for initial_location in sources:\n",
    "        visited[initial_location] = 0\n",
    "        push(queue, (0, next(c), initial_location))\n",
    "        \n",
    "    # search each node\n",
    "    while queue:\n",
    "        # select source - given distance and source\n",
    "        (path_distance, _, source) = pop(queue)\n",
    "        \n",
    "        # already searched this node.\n",
    "        if source in total_distance:\n",
    "            continue  \n",
    "            \n",
    "        # add distance associated with node (v)\n",
    "        total_distance[source] = path_distance  \n",
    "        \n",
    "        # found destination\n",
    "        if source == target:\n",
    "            break\n",
    "            \n",
    "        # From node(v) loop through child \n",
    "        # destination: destination node, e: edge data, v: source node\n",
    "        for destination, edge_data in G_succ[source].items():\n",
    "            \n",
    "            # very important - tells how minimization occurs\n",
    "            cost = weight(source, destination, edge_data)\n",
    "            print(source, destination, edge_data, 'cost: ', cost)\n",
    "            \n",
    "            # no other paths\n",
    "            if cost is None:\n",
    "                continue\n",
    "                \n",
    "            # sum past distance with new cost and assign to this loop variable\n",
    "            source_to_destination_distance = total_distance[source] + cost  \n",
    "                    \n",
    "            #  check if negative weights\n",
    "            if destination in total_distance:\n",
    "                # grab existing node distance\n",
    "                destination_distance = total_distance[destination]\n",
    "                \n",
    "                # check if source-destination distance is less than the \n",
    "                if source_to_destination_distance < destination_distance:\n",
    "                    raise ValueError(\"Contradictory paths found:\", \"negative weights?\")  \n",
    "                    \n",
    "            # not in visited(aka source initally) or vu distance less than destination distance\n",
    "            elif destination not in visited or source_to_destination_distance < visited[destination]:\n",
    "                \n",
    "                # update visited source node distance\n",
    "                visited[destination] = source_to_destination_distance\n",
    "                \n",
    "                # update queue to include new distance, iterator, and destination\n",
    "                # basically recursion but done by while loop checking queue\n",
    "                push(queue, (source_to_destination_distance, next(c), destination))\n",
    "                \n",
    "                # paths is passed source node initially\n",
    "                # the paths referenced below is a global variable\n",
    "                if paths is not None:\n",
    "                    paths[destination] = paths[source] + [destination]\n",
    "                    \n",
    "    return total_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "London Paris {'population': 8982000, 'distance': 7861.201009301914, 'pop_per_distance': 1142.5735061820553} cost:  1142.5735061820553\n",
      "London New_York {'population': 8399000, 'distance': 10478.287221079576, 'pop_per_distance': 801.562299523858} cost:  801.562299523858\n",
      "London Rio_de_Janeiro {'population': 6748000, 'distance': 7861.201009301914, 'pop_per_distance': 858.3930104338131} cost:  858.3930104338131\n",
      "New_York London {'population': 8399000, 'distance': 10478.287221079576, 'pop_per_distance': 801.562299523858} cost:  801.562299523858\n",
      "New_York Paris {'population': 8399000, 'distance': 4974.451033454915, 'pop_per_distance': 1688.427515622086} cost:  1688.427515622086\n",
      "New_York Los_Angeles {'population': 8399000, 'distance': 28681.685706832082, 'pop_per_distance': 292.83495000432725} cost:  292.83495000432725\n",
      "New_York Rio_de_Janeiro {'population': 8399000, 'distance': 4974.451033454915, 'pop_per_distance': 1688.427515622086} cost:  1688.427515622086\n",
      "Rio_de_Janeiro London {'population': 6748000, 'distance': 7861.201009301914, 'pop_per_distance': 858.3930104338131} cost:  858.3930104338131\n",
      "Rio_de_Janeiro Paris {'population': 6748000, 'distance': 0.0, 'pop_per_distance': inf} cost:  inf\n",
      "Rio_de_Janeiro Dubai {'population': 6748000, 'distance': 23768.664148269367, 'pop_per_distance': 283.9032079340198} cost:  283.9032079340198\n",
      "Rio_de_Janeiro New_York {'population': 8399000, 'distance': 4974.451033454915, 'pop_per_distance': 1688.427515622086} cost:  1688.427515622086\n",
      "final:  (1094.3972495281853, ['London', 'New_York', 'Los_Angeles'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ejwda\\AppData\\Local\\Temp\\ipykernel_16256\\2030934238.py:43: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  data['pop_per_distance'] = population / distance\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "# Custom graph data\n",
    "graph = {\n",
    "    'London': {'Paris': {'population': 2141000, 'lat': 48.8566, 'lon': 2.3522}, 'New_York': {'population': 8399000, 'lat': 40.7128, 'lon': -74.0060}, 'Rio_de_Janeiro': {'population': 6748000, 'lat': -22.9068, 'lon': -43.1729}},\n",
    "    'Paris': {'Dubai': {'population': 3330000, 'lat': 25.2048, 'lon': 55.2708}, 'Rio_de_Janeiro': {'population': 6748000, 'lat': -22.9068, 'lon': -43.1729}, 'London': {'population': 8982000, 'lat': 51.5074, 'lon': -0.1278}, 'New_York': {'population': 8399000, 'lat': 40.7128, 'lon': -74.0060}, 'Rio_de_Janeiro': {'population': 6748000, 'lat': -22.9068, 'lon': -43.1729}},\n",
    "    'New_York': {'Los_Angeles': {'population': 3990000, 'lat': 34.0522, 'lon': -118.2437}},\n",
    "    'Dubai': {'Rio_de_Janeiro': {'population': 6748000, 'lat': -22.9068, 'lon': -43.1729}, 'Tokyo': {'population': 13960000, 'lat': 35.6895, 'lon': 139.6917}},\n",
    "    'Rio_de_Janeiro': {'New_York': {'population': 8399000, 'lat': 40.7128, 'lon': -74.0060}},\n",
    "    'Tokyo': {'Dubai': {'population': 3330000, 'lat': 25.2048, 'lon': 55.2708}, 'Los_Angeles': {'population': 3990000, 'lat': 34.0522, 'lon': -118.2437}},\n",
    "    'Los_Angeles': {'New_York': {'population': 8399000, 'lat': 40.7128, 'lon': -74.0060}, 'Tokyo': {'population': 13960000, 'lat': 35.6895, 'lon': 139.6917}}\n",
    "}\n",
    "\n",
    "# Create network graph\n",
    "G = nx.Graph()\n",
    "\n",
    "# create dictionary of city and locations\n",
    "# Calculate pairwise distances between cities using Haversine formula\n",
    "city_lookup={}\n",
    "for source, data in graph.items():\n",
    "    for destination, info in data.items():\n",
    "        city_lookup[source] = [info['lat'], info['lon']]\n",
    "\n",
    "\n",
    "# Add nodes and edges\n",
    "for source, destination_data in graph.items():\n",
    "    G.add_node(source)\n",
    "    for destination, data in destination_data.items():\n",
    "        G.add_node(destination)\n",
    "        locations = np.stack((city_lookup[destination], city_lookup[source]))\n",
    "        distances = cdist(np.radians(locations), np.radians(locations), metric='euclidean') * 6371  # Earth radius in km\n",
    "        # create edges\n",
    "        G.add_edge(source, destination, population=data['population'], distance=distances[0,1])\n",
    "\n",
    "\n",
    "# Calculate population per distance for each edge\n",
    "for u, v, data in G.edges(data=True):\n",
    "    distance = data['distance']\n",
    "    population = data['population']\n",
    "    data['pop_per_distance'] = population / distance\n",
    "\n",
    "# Set the minimum number of cities in the path\n",
    "min_num_cities = 1\n",
    "start_city = 'London'\n",
    "end_city = 'Los_Angeles'\n",
    "\n",
    "# Find the path with the largest population per distance traveled while ensuring minimum cities\n",
    "shortest_paths = multi_source_dijkstra(G, start_city, end_city, weight='pop_per_distance')\n",
    "print('final: ', shortest_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
